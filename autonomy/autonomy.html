

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Autonomy Building Blocks &mdash; Project Airsim 0.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />

  
      <script src="../_static/documentation_options.js?v=2709fde1"></script>
      <script src="../_static/doctools.js?v=9bcbadda"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            Project Airsim
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Sensors</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../sensors/camera_capture_settings.html">Supported imaging/capture camera customizations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sensors/camera_capture_settings.html#sample-config">Sample config</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sensors/camera_post_processing_with_nn.html">Camera Images Post processing using Neural Network models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sensors/camera_post_processing_with_nn.html#image-post-processing-settings">Image post processing settings</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sensors/camera_post_processing_with_nn.html#post-processing-model-settings">Post processing model settings</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sensors/camera_streaming.html">Camera Streaming</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sensors/segmentation.html">Segmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sensors/lidar.html">Lidar sensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sensors/lidar.html#lidar-sensor-settings">Lidar sensor settings</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sensors/radar.html">Radar sensor overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sensors/radar.html#radar-sensor-settings">Radar sensor settings</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sensors/battery.html">Battery sensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sensors/battery.html#battery-sensor-settings">Battery sensor settings</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Physics and Simulation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../physics/fast_physics.html">Fast Physics for Drones</a></li>
<li class="toctree-l1"><a class="reference internal" href="../physics/matlab_physics.html">Matlab Physics for Drones</a></li>
<li class="toctree-l1"><a class="reference internal" href="../scene/sim_clock.html">Simulation Clock</a></li>
<li class="toctree-l1"><a class="reference internal" href="../scene/weather_visual_effects.html">Weather Visual Effects</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Controllers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../controllers/controllers.html">Flight Controllers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../controllers/simple_flight.html">Simple Flight Controller for Drones</a></li>
<li class="toctree-l1"><a class="reference internal" href="../controllers/px4/px4.html">PX4 Autopilot Flight Controller</a></li>
<li class="toctree-l1"><a class="reference internal" href="../controllers/px4/px4_build.html">Building PX4</a></li>
<li class="toctree-l1"><a class="reference internal" href="../controllers/px4/px4_hitl.html">Using a PX4 Controller as Hardware-In-The-Loop (HITL)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../controllers/px4/px4_lockstep.html">PX4 Lockstep Mode</a></li>
<li class="toctree-l1"><a class="reference internal" href="../controllers/px4/px4_multi_vehicle.html">PX4 with Multiple Robots</a></li>
<li class="toctree-l1"><a class="reference internal" href="../controllers/px4/px4_sitl.html">Using a PX4 Controller as Software-In-The-Loop (SITL)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../controllers/px4/px4_sitl_wsl2.html">PX4 Software-in-the-Loop with WSL 2</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Settings</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://iamaisim.github.io/ProjectAirSim/api_docs/index.html">Python Client API Reference</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Project Airsim</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Autonomy Building Blocks</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/autonomy/autonomy.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="autonomy-building-blocks">
<h1>Autonomy Building Blocks<a class="headerlink" href="#autonomy-building-blocks" title="Link to this heading">¶</a></h1>
<p>The Autonomy module of Project AirSim, aims to provide <a class="reference internal" href="#pre-trained-models"><span class="xref myst">pre-trained models</span></a>, fine-tuning scripts, <a class="reference internal" href="#rl-gym-environments"><span class="xref myst">RL Gym environments</span></a>, <a class="reference internal" href="#2-data-collection"><span class="xref myst">data collection scripts</span></a> and <a class="reference internal" href="#3-sample-applications"><span class="xref myst">sample/demo</span></a> applications for you to try out and leverage to build custom models for your autonomy needs and use-cases.
The pre-trained model allow you to develop efficient, scenario/task-specific models with relatively less amount of new data from your scenarios.</p>
<section id="pre-trained-models">
<h2>Pre-trained Models<a class="headerlink" href="#pre-trained-models" title="Link to this heading">¶</a></h2>
<p>Ready-to-use/ready-to-finetune neural network models for your applications.</p>
<section id="perception">
<h3>1. Perception<a class="headerlink" href="#perception" title="Link to this heading">¶</a></h3>
<p>Camera sensor-based visual processing models for the object detection. Object detection include tasks like detecting landing pads, drones, vehicles, people, trees, builoing, power poles etc.
The current release of the autonomy module contains pre-trained models for the following perception tasks: 1. Landing pad detection</p>
<section id="landing-pad-detection">
<h4>1.1 Landing pad detection<a class="headerlink" href="#landing-pad-detection" title="Link to this heading">¶</a></h4>
<p>The landing pad detection model detects and localizes a landing pad on the image captured by a downward-facing camera mounted on a drone flying in Project AirSim. The pre-trained model by default is trained to detect the <code class="docutils literal notranslate"><span class="pre">BasicLandingPad</span></code> that is available as part of the Project AirSim Sim package assets.
The visual of the <code class="docutils literal notranslate"><span class="pre">BasicLandingPad</span></code> is shown below:</p>
<p><img alt="BasicLandingPad" src="../_images/basiclandingpad.png" /></p>
<p>The pre-trained model is capable of detecting the landing pad under varying environmental  conditions like snow, rain and typical variations in lighting. Sample predictions are shown below for reference:</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p><img alt="" src="../_images/basiclandingpad-perception-model-output-set1.jpg" /></p></th>
<th class="head"><p><img alt="" src="../_images/basiclandingpad-perception-model-output-set2.jpg" /></p></th>
<th class="head"><p><img alt="" src="../_images/basiclandingpad-perception-model-output-set3.jpg" /></p></th>
</tr>
</thead>
</table>
<section id="running-the-landing-pad-detection-demo">
<h5>1.1.1 Running the landing pad detection demo<a class="headerlink" href="#running-the-landing-pad-detection-demo" title="Link to this heading">¶</a></h5>
<p>The landing pad prediction demo script uses a pre-trained model to predict the bounding boxes around the landing pads present in the input set of images. You will need a pre-trained model and a directory containing a sample set of images to run this demo.</p>
<p>Please follow the steps in the <a class="reference internal" href="setup.html"><span class="std std-doc">ProjectAirSim Autonomy Setup</span></a> documentation page to setup your python environment before proceeding to the next steps below.</p>
<ol class="arabic simple">
<li><p>Obtain the latest pre-trained model and save it to your local disk, for example at: <code class="docutils literal notranslate"><span class="pre">client/python/example_user_scripts/autonomy/pretrained-basiclandingpad-perception-model.pth.tar</span></code></p></li>
<li><p>Obtain a set of test images with the <code class="docutils literal notranslate"><span class="pre">BasicLandingPad</span></code> to run this demo. You can use the images in <a class="reference internal" href="#input_images"><span class="xref myst">client/python/example_user_scripts/autonomy/input_images</span></a> for the demo.</p></li>
<li><p>Run the <code class="docutils literal notranslate"><span class="pre">landingpad_predictor</span></code> demo script with the <code class="docutils literal notranslate"><span class="pre">airsim-venv</span></code> python environment activated: <code class="docutils literal notranslate"><span class="pre">(airsim-venv)$</span> <span class="pre">cd</span>&#160; <span class="pre">client/python/example_user_scripts/autonomy</span> <span class="pre">&amp;&amp;</span> <span class="pre">python</span> <span class="pre">landingpad_predictor.py</span> <span class="pre">--images=input_images</span> <span class="pre">--pretrained-model=pretrained-basiclandingpad-perception-model.pth.tar</span> <span class="pre">--interactive</span></code></p></li>
</ol>
<p>The above demo script will interactively display the predicted bounding box on the input RGB image and wait for your keyboard key press to advance to the next image. You can also run the above script without the <code class="docutils literal notranslate"><span class="pre">--interactive</span></code> argument to have the predictions saved to the <code class="docutils literal notranslate"><span class="pre">client/python/example_user_scripts/autonomy/outputs/</span></code> directory.</p>
</section>
<section id="workflow-for-building-your-own-landing-pad-detection-models">
<h5>1.1.2 Workflow for building your own landing pad detection models:<a class="headerlink" href="#workflow-for-building-your-own-landing-pad-detection-models" title="Link to this heading">¶</a></h5>
<ol class="arabic simple">
<li><p>Obtain the latest pre-trained model and save it to your local disk, for example at: <code class="docutils literal notranslate"><span class="pre">client/python/example_user_scripts/autonomy/pretrained-basiclandingpad-perception-model.pth.tar</span></code></p></li>
<li><p>Collect new data for your scenario (e.g: your custom landing pad asset) using the <a class="reference internal" href="#fix-me"><span class="xref myst">Data Collector</span></a></p></li>
<li><p>Fine-tune/customize the pre-trained model to work for your scenario using the <a class="reference internal" href="#fix-me"><span class="xref myst">Finetuning script</span></a></p></li>
</ol>
<p>We currently offer pre-trained models for the landing pad detection task. Pre-trained models for additional tasks and updated models for existing tasks will be made available thourgh our upcoming releases.</p>
</section>
</section>
</section>
<section id="data-collection">
<h3>2. Data collection<a class="headerlink" href="#data-collection" title="Link to this heading">¶</a></h3>
<p>Sample data collection scripts and workflow.</p>
<p><em>Coming soon! Stay tuned for the next release</em></p>
</section>
<section id="sample-applications">
<h3>3. Sample Applications<a class="headerlink" href="#sample-applications" title="Link to this heading">¶</a></h3>
<ol class="arabic simple">
<li><p>Using a perception module for visual Take-off and landing</p></li>
</ol>
<p>This application allows a drone equipped with a single, downward-facing RGB color camera to precisely detect the landing pad and provide localization information, which can be used  by a navigation controller for visual precision landing.</p>
<p><img alt="" src="../_images/takeoff-landing-app-cam-view.gif" /></p>
<p>This application runs the model in-the-loop with the sim. After each movement command, the drone gets an image from its downward-facing RBG camera, runs that image through the model and displays the predicted landing pad location as a bounding box.</p>
<p>The application is configured through <a class="reference download internal" download="" href="../_downloads/4fc73389b82fb5f872a6b5979b245ec7/perception_app_config.jsonc"><span class="xref download myst"><code class="docutils literal notranslate"><span class="pre">perception_app_config.jsonc</span></code></span></a>. This config file provides a sample implementation of how the motions in the application script, <a class="reference download internal" download="" href="../_downloads/67649331d58eaf11dc8eaae985d15d19/takeoff_landing_sync.py"><span class="xref download myst"><code class="docutils literal notranslate"><span class="pre">takeoff_landing_sync.py</span></code></span></a> can be defined. To run the sim and model in sync, the motion of the drone is broken up into smaller steps which are defined through the config.</p>
<p>If you have not done so already, please follow the steps in the <a class="reference internal" href="setup.html"><span class="std std-doc">ProjectAirSim Autonomy Setup</span></a> documentation page to setup your python environment before proceeding to the next steps below.</p>
<ol class="arabic simple">
<li><p>Run the Project AirSim Sim server: <code class="docutils literal notranslate"><span class="pre">Blocks.sh</span></code> / <code class="docutils literal notranslate"><span class="pre">Blocks.exe</span></code></p></li>
<li><p>Update the <code class="docutils literal notranslate"><span class="pre">client/python/example_user_scripts/autonomy/configs/perception_app_config.jsonc</span></code> if necessary, <code class="docutils literal notranslate"><span class="pre">&quot;perception-pretrained-model&quot;</span></code>:</p></li>
<li><p>With the <code class="docutils literal notranslate"><span class="pre">airsim-venv</span></code> python environment activated, launch the Takeoff-Landing demo app:
<code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">client/python/example_user_scripts/autonomy/takeoff_landing_sync.py</span></code></p></li>
</ol>
</section>
</section>
<section id="rl-gym-environments">
<h2>RL Gym environments<a class="headerlink" href="#rl-gym-environments" title="Link to this heading">¶</a></h2>
<p>The Autonomy Gym environments provide configurable Markov Decision Processes with an interface compatible with the <a class="reference external" href="https://gym.openai.com">OpenAI Gym</a> specifications. This allows the user to use any Reinforcement Learning algorithm to train an Agent to solve tasks like obstacle avoidance, drone landing etc.</p>
<p>Please visit the <a class="reference internal" href="gym/gym_envs.html"><span class="std std-doc">gym_envs doc</span></a> for more details on the Autonomy Gym environments.</p>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright .</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>